<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sportnomics</title>
    <link>https://gharv.github.io/</link>
    <description>Recent content on Sportnomics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Jul 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://gharv.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scraping PGA Site</title>
      <link>https://gharv.github.io/2017/07/scraping-pga-site/</link>
      <pubDate>Tue, 25 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://gharv.github.io/2017/07/scraping-pga-site/</guid>
      <description>To begin we want to use the json data from the PGA tour website. After doing some investigation into the PGA tour website, there are both pros and cons of using it for scraping.
From what I have found we will only be able to get shot data from 2014 and beyond. This will contain any data we would want but only goes back to 2014, before 2014 there isnt even data for simple scorecards for players.</description>
    </item>
    
    <item>
      <title>The Hole Cloud</title>
      <link>https://gharv.github.io/2017/07/the-hole-cloud/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://gharv.github.io/2017/07/the-hole-cloud/</guid>
      <description>In this post I will create word clouds to help determine what may or may not be important in predicting PGA golfers performance. I will start with gathering data from the PGA tour website.
In this example I will be using descriptions from TPC Sawgrass golf course which hosts the Players Championship every year and is one of the most iconic course in the game. The hole descriptions in website format can be found here.</description>
    </item>
    
  </channel>
</rss>